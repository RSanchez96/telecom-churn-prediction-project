{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Customer Churn Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the present project is to maximize the\n",
    "\n",
    "The Telco customer churn data contains information about a fictional telco company that provided home phone and Internet services to 7043 customers in California in Q3. It indicates which customers have left, stayed, or signed up for their service.\n",
    "\n",
    "Information about the Dataset Here  here: https://ieee-dataport.org/documents/wafn-usec-telco-customer-churn  \n",
    "I created a dictionary for the variables that can be find in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.5.2\n",
      "Uninstalling scikit-learn-1.5.2:\n",
      "  Successfully uninstalled scikit-learn-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==1.5.2\n",
      "  Using cached scikit_learn-1.5.2-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\vicsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (2.2.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\vicsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (1.15.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\vicsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\vicsa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn==1.5.2) (3.5.0)\n",
      "Using cached scikit_learn-1.5.2-cp313-cp313-win_amd64.whl (11.0 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "Successfully installed scikit-learn-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~cikit-learn (C:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Due to changes in the version 1.6 of Scikit-learn an inferior version must be used for XGBClassifier to function correctly.\n",
    "!pip uninstall -y scikit-learn\n",
    "!pip install scikit-learn==1.5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'RandomForestClassifier' from 'xgboost' (c:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stats\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score, make_scorer\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'RandomForestClassifier' from 'xgboost' (c:\\Users\\vicsa\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\xgboost\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# I import the libraries that will be used in this project \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"C:/Users/vicsa/OneDrive/Documents/Personal/Projects/telecom-churn-prediction-project\"\n",
    "df = pd.read_csv(\"WA_telco_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculos estadisticos de la base de datos\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MonthlyCharges\"].hist(figsize=(8,5));\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tenure\"].hist(figsize=(8,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Contract\"].hist(figsize=(8,5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InternetService'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Contract'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['PaymentMethod'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Churn'].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I create dummies for the boolean columns\n",
    "df = pd.get_dummies(df, prefix=['gender', 'PaymentMethod', 'InternetService','Contract'], columns=['gender', 'PaymentMethod', 'InternetService','Contract'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I eliminate the column gender_Male for correlation with gender_Female\n",
    "df = df.drop('gender_Male', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nophoneserveice /NoInternetService in columns that have it\n",
    "df['MultipleLines'] = df['MultipleLines'].map({'No': 0, 'No phone service': 0, 'Yes': 1})\n",
    "df['OnlineSecurity'] = df['OnlineSecurity'].map({'No': 0, 'No internet service': 0, 'Yes': 1})\n",
    "df['OnlineBackup'] = df['OnlineBackup'].map({'No': 0, 'No internet service': 0, 'Yes': 1})\n",
    "df['DeviceProtection'] = df['DeviceProtection'].map({'No': 0, 'No internet service': 0, 'Yes': 1})\n",
    "df['TechSupport'] = df['TechSupport'].map({'No': 0, 'No internet service': 0, 'Yes': 1})\n",
    "df['StreamingTV'] = df['StreamingTV'].map({'No': 0, 'No internet service': 0, 'Yes': 1})\n",
    "df['StreamingMovies'] = df['StreamingMovies'].map({'No': 0, 'No internet service': 0, 'Yes': 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Partner'] = df['Partner'].map({'No': 0, 'Yes': 1})\n",
    "df['Dependents'] = df['Dependents'].map({'No': 0, 'Yes': 1})\n",
    "df['PhoneService'] = df['PhoneService'].map({'No': 0, 'Yes': 1}) \n",
    "df['PaperlessBilling'] = df['PaperlessBilling'].map({'No': 0, 'Yes': 1}) \n",
    "df['Churn'] = df['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['TotalCharges']] = df[['TotalCharges']].apply(lambda col: pd.to_numeric(col, errors='coerce'))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ChargesAmount'] = df['TotalCharges']/df['MonthlyCharges']\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Strategy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df.select_dtypes(include=['float64', 'int64', 'int32', 'int16', 'int8', 'bool'])\n",
    "\n",
    "primary_seed = 990653\n",
    "X = df_training[df_training.columns.drop('Churn')]\n",
    "y = df_training['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I Split the dataset into Train, Validation and Test.\n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=primary_seed\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_trainval, y_trainval, test_size=1/3, random_state=primary_seed\n",
    ")\n",
    "\n",
    "print(len(X_train), len(X_val), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why Bayesian and why XGBoos (Handle NA values, velocity,etc)\n",
    "max_depth': sp_randint(3,6),\n",
    "              'learning_rate': sp_randfloat(0.01, 0.1),\n",
    "              'n_estimators': sp_randint(100, 1000),\n",
    "              'subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "              'reg_alpha': sp_randfloat(0.0, 1.0),\n",
    "              'reg_lambda': sp_randfloat(0.0, 1.0),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2', None]),\n",
    "        'bootstrap': trial.suggest_categorical('bootstrap', [True, False])\n",
    "    }\n",
    "    clf = RandomForestClassifier(**param, random_state=primary_seed)\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=3, scoring='roc_auc').mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=primary_seed))\n",
    "study.optimize(objective, n_trials=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters and the model \n",
    "best_params = study.best_params\n",
    "clf = RandomForestClassifier(**best_params, random_state=primary_seed)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review with Validation Dataset\n",
    "# Predict probabilities for the validation set\n",
    "y_val_proba = clf.predict_proba(X_val)[:, 1]  # probabilities for the positive class\n",
    "\n",
    "# Calculate ROC AUC for validation set\n",
    "val_auc = roc_auc_score(y_val, y_val_proba)\n",
    "print(f\"Validation ROC AUC: {val_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Training with Validation Data\n",
    "# Combine the features\n",
    "X_combined = np.concatenate([X_train, X_val], axis=0)\n",
    "# Combine the labels\n",
    "y_combined = np.concatenate([y_train, y_val], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrain the Final Model\n",
    "# Initialize with best parameters (as before)\n",
    "clf_final = RandomForestClassifier(**best_params, random_state=primary_seed)\n",
    "\n",
    "# Train on the combined training and validation dataset\n",
    "clf_final.fit(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict in Final Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities for the test set\n",
    "y_test_proba = clf_final.predict_proba(X_test)[:, 1]  # Probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance using ROC-AUC\n",
    "test_auc = roc_auc_score(y_test, y_test_proba)\n",
    "print(f\"Test ROC AUC: {test_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get an Outcome that is workable for Finance reasons or something like that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict churn for the test set\n",
    "y_test_pred = clf_final.predict(X_test)\n",
    "\n",
    "# Create a DataFrame with actual and predicted values\n",
    "output_df = pd.DataFrame({\n",
    "    'Predicted_Churn': y_test_pred,\n",
    "    'Actual_Churn': y_test.values\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define revenue calculation function\n",
    "def calculate_revenue(predicted, actual):\n",
    "    if predicted == 1 and actual == 1:\n",
    "        return 100000\n",
    "    elif predicted == 0 and actual == 0:\n",
    "        return 0\n",
    "    elif predicted == 1 and actual == 0:\n",
    "        return -5000 #change to 5000\n",
    "\n",
    "# Apply revenue function to each row\n",
    "output_df['Revenue_Score'] = output_df.apply(lambda row: calculate_revenue(row['Predicted_Churn'], row['Actual_Churn']), axis=1)\n",
    "\n",
    "# Calculate total revenue\n",
    "total_revenue = output_df['Revenue_Score'].sum()\n",
    "\n",
    "# Display total revenue\n",
    "print(f\"Total Revenue: ${total_revenue}\")\n",
    "\n",
    "# Save to CSV file\n",
    "output_df.to_csv(\"telco_churn_predictions_revenue.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
